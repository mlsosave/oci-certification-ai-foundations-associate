# MÃ³dulo 4: IA Generativa y Fundamentos de Modelos de Lenguaje Grande (LLM)

## ğŸ“‹ InformaciÃ³n del MÃ³dulo

**Peso en el examen:** 15%  
**Conceptos evaluados:**
- DescripciÃ³n general de IA Generativa
- Fundamentos de Modelos de Lenguaje Grande (LLM)
- Fundamentos de Transformers
- Prompt Engineering e Instruction Tuning
- Fine-tuning de LLMs

---

## ğŸ¯ Objetivos de Aprendizaje

Al finalizar este mÃ³dulo, podrÃ¡s:
1. Explicar quÃ© es la IA Generativa y cÃ³mo funciona
2. Comprender los Modelos de Lenguaje Grande (LLM)
3. Entender la arquitectura Transformer
4. Dominar conceptos de Prompt Engineering
5. Conocer mÃ©todos de fine-tuning y personalizaciÃ³n de LLMs

---

## 1. IntroducciÃ³n a la IA Generativa

### Â¿QuÃ© es IA Generativa?

**DefiniciÃ³n:**
La **IA Generativa (GenAI)** es un tipo de inteligencia artificial que puede **crear contenido nuevo** como texto, imÃ¡genes, mÃºsica, videos y otros tipos de datos.

### AnalogÃ­a Simple

**Machine Learning tradicional:**
```
Entrada: Imagen de un perro
Salida: Etiqueta "perro"
```

**IA Generativa:**
```
Entrada: DescripciÃ³n "Un perro jugando en el parque"
Salida: Imagen NUEVA de un perro jugando en el parque
```

---

### Â¿CÃ³mo Funciona la IA Generativa?

```
1. Entrenamiento
   â”œâ”€â”€ Modelo ve miles de imÃ¡genes de perros
   â”œâ”€â”€ Aprende patrones: orejas, cola, pelaje
   â””â”€â”€ No copia imÃ¡genes, aprende conceptos
   
2. GeneraciÃ³n
   â”œâ”€â”€ Usuario pide: "perro jugando"
   â”œâ”€â”€ Modelo usa patrones aprendidos
   â””â”€â”€ Crea imagen NUEVA basada en conceptos
```

**Punto clave:** El modelo NO estÃ¡ copiando. EstÃ¡ **generando** basÃ¡ndose en patrones aprendidos.

---

### IA Generativa vs Machine Learning

| Aspecto | Machine Learning | IA Generativa |
|---------|------------------|---------------|
| **Objetivo** | Clasificar / Predecir | Crear contenido nuevo |
| **Entrada** | Datos + Etiquetas | Datos sin etiquetas (pre-training) |
| **Salida** | Etiqueta / NÃºmero | Texto / Imagen / Audio |
| **Ejemplo** | "Esta es una foto de gato" | "Crea una imagen de un gato" |
| **Proceso** | Aprende relaciÃ³n datosâ†’etiqueta | Aprende patrones en contenido |

---

### Tipos de Modelos Generativos

#### 1. Basados en Texto
**Generan contenido textual:**
- Historias y poemas
- CÃ³digo de programaciÃ³n
- ArtÃ­culos
- DiÃ¡logos y chat

**Ejemplos:**
- ChatGPT
- GPT-4
- Claude
- Llama

---

#### 2. Multimodales
**Procesan y generan mÃºltiples tipos de contenido:**
- Texto â†” Imagen
- Texto â†” Audio
- Texto â†” Video

**Ejemplos:**
- DALL-E (Texto â†’ Imagen)
- Midjourney (Texto â†’ Imagen)
- Stable Diffusion (Texto â†’ Imagen)
- Whisper (Audio â†’ Texto)

---

### Aplicaciones de IA Generativa

| Vertical | AplicaciÃ³n |
|----------|------------|
| **CreaciÃ³n de contenido** | ArtÃ­culos, blogs, marketing |
| **Arte y diseÃ±o** | ImÃ¡genes, logos, diseÃ±os |
| **ProgramaciÃ³n** | GeneraciÃ³n de cÃ³digo, debugging |
| **Medicina** | DiseÃ±o de medicamentos, anÃ¡lisis de imÃ¡genes |
| **EducaciÃ³n** | Tutores personalizados, contenido educativo |
| **Entretenimiento** | Guiones, mÃºsica, videojuegos |

---

## 2. Modelos de Lenguaje Grande (LLM)

### Â¿QuÃ© es un Modelo de Lenguaje?

**DefiniciÃ³n:**
Un **modelo de lenguaje** es un modelo probabilÃ­stico que determina la probabilidad de una secuencia de palabras.

### AnalogÃ­a: Completar la OraciÃ³n

```
OraciÃ³n: "Fui al zoolÃ³gico y me enviaron un _____"

Probabilidades:
- leÃ³n: 0.03
- elefante: 0.02
- perro: 0.45
- gato: 0.25
- pantera: 0.15
```

El modelo calcula probabilidades para **cada palabra en su vocabulario**.

---

### CÃ³mo Funciona la PredicciÃ³n

**Paso 1: Calcular probabilidades**
```
Entrada: "Fui al zoolÃ³gico y me enviaron un"
â†“
Modelo LLM
â†“
Probabilidades para cada palabra
```

**Paso 2: Seleccionar la palabra con mayor probabilidad**
```
Palabra seleccionada: "perro" (0.45)
```

**Paso 3: Agregar a la entrada y repetir**
```
Nueva entrada: "Fui al zoolÃ³gico y me enviaron un perro"
â†“
Modelo LLM
â†“
Probabilidades:
- EOS (End of Sentence): 0.85 â† ALTA
- gato: 0.05
- y: 0.10
```

**Paso 4: Terminar cuando aparece EOS**
```
Salida final: "Fui al zoolÃ³gico y me enviaron un perro"
```

---

### Â¿QuÃ© es "Large" (Grande) en LLM?

**"Large" se refiere al nÃºmero de parÃ¡metros.**

**ParÃ¡metros:** Pesos ajustables en la red neuronal.

**EvoluciÃ³n del tamaÃ±o:**

| AÃ±o | Modelo | ParÃ¡metros |
|-----|--------|------------|
| 2018 | GPT-1 | 117 millones |
| 2019 | GPT-2 | 1.5 mil millones |
| 2020 | GPT-3 | 175 mil millones |
| 2023 | GPT-4 | >1 trillÃ³n (no confirmado) |

**Nota importante:**
MÃ¡s parÃ¡metros â‰  Siempre mejor desempeÃ±o

Puede causar **overfitting** si el modelo es demasiado grande.

---

### Capacidades de LLMs

#### 1. Responder Preguntas
```
Usuario: Â¿CuÃ¡l es la capital de Francia?
LLM: La capital de Francia es ParÃ­s.
```

#### 2. Razonamiento Complejo
```
Usuario: Tengo 3 manzanas. Compro 2 bolsas con 5 manzanas cada una. 
        Le doy 4 a mi amigo. Â¿CuÃ¡ntas me quedan?

LLM: Empiezas con 3 manzanas.
     Compras 2 bolsas Ã— 5 = 10 manzanas mÃ¡s.
     Total: 3 + 10 = 13 manzanas.
     Das 4 a tu amigo.
     Te quedan: 13 - 4 = 9 manzanas.
```

#### 3. Generar ArtÃ­culos
```
Usuario: Escribe un artÃ­culo sobre la RevoluciÃ³n Francesa

LLM: La RevoluciÃ³n Francesa fue un perÃ­odo de cambio radical...
     [Genera artÃ­culo completo]
```

#### 4. Traducir Idiomas
```
Usuario: Traduce "How are you" al francÃ©s

LLM: "Comment allez-vous" (formal) o "Comment Ã§a va" (informal)
```

---

## 3. Arquitectura Transformer

### Â¿Por QuÃ© Transformers?

**Problema con RNN:**
```
OraciÃ³n: "Jane lanzÃ³ el frisbee y su perro lo recogiÃ³"

RNN procesa asÃ­:
Paso 1: Jane
Paso 2: Jane â†’ lanzÃ³
Paso 3: Jane â†’ lanzÃ³ â†’ el
...

Problema: Procesa SECUENCIALMENTE (lento)
         Olvida informaciÃ³n lejana
```

---

### SoluciÃ³n: Transformers

**Transformers pueden ver TODA la oraciÃ³n al mismo tiempo.**

```
OraciÃ³n: "Jane lanzÃ³ el frisbee y su perro lo recogiÃ³"

Transformer ve:
Jane â†â†’ lanzÃ³ â†â†’ frisbee â†â†’ perro â†â†’ recogiÃ³
  â†•       â†•         â†•         â†•        â†•
Todas las conexiones simultÃ¡neamente
```

**Ventajas:**
- âœ… Ve toda la oraciÃ³n a la vez
- âœ… ParalelizaciÃ³n (mÃ¡s rÃ¡pido)
- âœ… Captura relaciones a largo plazo
- âœ… Entiende contexto completo

---

### Mecanismo de Auto-AtenciÃ³n (Self-Attention)

**Self-Attention** le permite al modelo **enfocarse** en partes importantes de la entrada.

**Ejemplo:**
```
OraciÃ³n: "Jane lanzÃ³ el frisbee y su perro lo recogiÃ³"

Pregunta: Â¿A quÃ© se refiere "lo"?
```

**Self-Attention:**
```
"lo" presta atenciÃ³n a:
- frisbee (ALTA atenciÃ³n) âœ…
- perro (Media atenciÃ³n)
- Jane (Baja atenciÃ³n)
- lanzÃ³ (Baja atenciÃ³n)

ConclusiÃ³n: "lo" = frisbee
```

---

### Componentes del Transformer

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     TRANSFORMER         â”‚
â”‚                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    ENCODER       â”‚   â”‚
â”‚  â”‚  - Procesa input â”‚   â”‚
â”‚  â”‚  - Crea          â”‚   â”‚
â”‚  â”‚    embeddings    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â†“             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    DECODER       â”‚   â”‚
â”‚  â”‚  - Genera output â”‚   â”‚
â”‚  â”‚  - Usa           â”‚   â”‚
â”‚  â”‚    embeddings    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Encoder (Codificador)

**FunciÃ³n:**
Procesa el **texto de entrada** y lo convierte en **representaciones numÃ©ricas** (embeddings).

**Proceso:**
```
Texto: "El gato come pescado"
   â†“
TokenizaciÃ³n: ["El", "gato", "come", "pescado"]
   â†“
Encoder
   â†“
Embeddings: [0.2, 0.5, ...], [0.8, 0.1, ...], ...
```

**Aplicaciones de Encoder-only:**
- BÃºsqueda semÃ¡ntica
- Bases de datos vectoriales
- ClasificaciÃ³n de texto

---

### Decoder (Decodificador)

**FunciÃ³n:**
Genera **texto de salida** palabra por palabra.

**Proceso:**
```
Embeddings de entrada
   â†“
Decoder
   â†“
Token 1: "El"
   â†“
Decoder (con "El" como input)
   â†“
Token 2: "gato"
   â†“
...continÃºa hasta EOS
```

**Aplicaciones de Decoder-only:**
- GeneraciÃ³n de texto
- ChatGPT
- Completar cÃ³digo

---

### Encoder-Decoder (Combinado)

**FunciÃ³n:**
Combina ambos para tareas de **secuencia a secuencia**.

**Ejemplo: TraducciÃ³n**
```
Entrada (InglÃ©s): "How are you?"
   â†“
Encoder â†’ Embeddings
   â†“
Decoder â†’ Salida (FrancÃ©s): "Comment allez-vous?"
```

**Aplicaciones:**
- TraducciÃ³n automÃ¡tica
- Resumen de texto
- ConversiÃ³n de formatos

---

## 4. Tokens y TokenizaciÃ³n

### Â¿QuÃ© es un Token?

**Token:** Unidad bÃ¡sica que entiende un LLM.

**Un token puede ser:**
- Una palabra completa: "apple"
- Parte de una palabra: "friend" + "ship"
- SÃ­mbolo de puntuaciÃ³n: "." o ","

---

### Ejemplos de TokenizaciÃ³n

**Texto simple:**
```
"I love AI"
Tokens: ["I", "love", "AI"]
Total: 3 tokens
```

**Texto complejo:**
```
"Machine learning is indivisible."

Tokens: ["Machine", "learning", "is", "in", "divisible", "."]
Total: 6 tokens
```

---

### Reglas Generales

| Tipo de Texto | Tokens por Palabra |
|---------------|-------------------|
| **Simple** | ~1 token/palabra |
| **Complejo** | ~2-3 tokens/palabra |

**Ejemplo prÃ¡ctico:**
```
"Many words map to one token, but indivisible words require multiple."

Tokens:
Many(1) words(1) map(1) to(1) one(1) token(1), (1) 
but(1) in(1)divisible(1) words(1) require(1) multiple(1).(1)

Total: 15 tokens
```

---

## 5. Embeddings

### Â¿QuÃ© son Embeddings?

**DefiniciÃ³n:**
**Embeddings** son representaciones numÃ©ricas de texto que capturan su significado.

### AnalogÃ­a: Mapa de Conceptos

Imagina un mapa donde:
- Palabras similares estÃ¡n **cerca**
- Palabras diferentes estÃ¡n **lejos**

```
        Gato
         â”‚
    â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”
  Perro Mascota Felino
    â”‚         â”‚
  Animal    Tigre
```

---

### Proceso de Embedding

```
Texto: "El perro come"
   â†“
TokenizaciÃ³n: ["El", "perro", "come"]
   â†“
Encoder Model
   â†“
Embeddings (vectores):
El    â†’ [0.1, 0.5, 0.3, 0.8, ...]
perro â†’ [0.2, 0.7, 0.1, 0.5, ...]
come  â†’ [0.9, 0.2, 0.6, 0.3, ...]
```

**Cada token â†’ Vector de nÃºmeros**

---

### AplicaciÃ³n: BÃºsqueda SemÃ¡ntica

**Problema tradicional (bÃºsqueda por palabras clave):**
```
BÃºsqueda: "auto"
Resultados: Solo documentos con palabra "auto"
No encuentra: "coche", "vehÃ­culo", "automÃ³vil"
```

**SoluciÃ³n con embeddings (bÃºsqueda semÃ¡ntica):**
```
1. Convertir todos los documentos a embeddings
2. Guardar en base de datos vectorial
3. Convertir consulta del usuario a embedding
4. Encontrar documentos con embeddings similares
5. Retornar resultados relevantes
```

**Ventaja:**
```
BÃºsqueda: "auto"
Resultados: 
- Documentos con "auto" âœ…
- Documentos con "coche" âœ…
- Documentos con "vehÃ­culo" âœ…
```

---

### RAG (Retrieval-Augmented Generation)

**Problema:**
LLMs solo conocen informaciÃ³n de su entrenamiento.

**SoluciÃ³n: RAG**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Usuario hace pregunta       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Buscar docs relevantes      â”‚
â”‚    en base vectorial           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Enviar pregunta + docs      â”‚
â”‚    al LLM                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. LLM genera respuesta        â”‚
â”‚    basada en docs              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ejemplo:**
```
Empresa: PolÃ­tica de devoluciones actualizada hoy

Sin RAG:
Usuario: Â¿CuÃ¡l es la polÃ­tica de devoluciones?
LLM: No tengo informaciÃ³n actualizada.

Con RAG:
Usuario: Â¿CuÃ¡l es la polÃ­tica de devoluciones?
Sistema: [Busca en docs] â†’ Encuentra polÃ­tica nueva
LLM: SegÃºn la polÃ­tica, puedes devolver en 30-90 dÃ­as...
```

---

## 6. Prompt Engineering

### Â¿QuÃ© es un Prompt?

**Prompt:** Texto de entrada que le das a un LLM.

**Prompt Engineering:** Proceso de diseÃ±ar prompts efectivos para obtener mejores resultados.

---

### EvoluciÃ³n: Completion â†’ Instruction

**Modelos de Completion (antiguos):**
```
Prompt: "Four score and seven years ago"
Salida: [Completa el discurso de Gettysburg]
```

**Problema:** Solo completa texto, no sigue instrucciones.

---

**Modelos Instruction-Tuned (modernos):**
```
Prompt: "ExplÃ­came quÃ© es fotosÃ­ntesis en tÃ©rminos simples"
Salida: "La fotosÃ­ntesis es el proceso por el cual las plantas 
         convierten luz solar en energÃ­a..."
```

**Ventaja:** Sigue instrucciones del usuario.

---

### Instruction Tuning

**Proceso:**
```
1. Modelo base entrenado en 2 trillones de tokens
   â†“
2. Fine-tuning con ~28,000 pares prompt-respuesta
   â†“
3. RLHF (Reinforcement Learning from Human Feedback)
   â”œâ”€â”€ Humanos escriben prompts
   â”œâ”€â”€ Humanos evalÃºan respuestas del modelo
   â”œâ”€â”€ Se entrena modelo de recompensa
   â””â”€â”€ Modelo aprende preferencias humanas
   â†“
4. Modelo instruction-tuned listo
```

---

### TÃ©cnicas de Prompt Engineering

#### 1. In-Context Learning

**DefiniciÃ³n:**
Proporcionar **ejemplos** de la tarea dentro del prompt.

**0-shot (sin ejemplos):**
```
Prompt: "Traduce al francÃ©s: cheese"
```

**Few-shot (con ejemplos):**
```
Prompt:
Traduce del inglÃ©s al francÃ©s:

Ejemplo 1:
English: hello
French: bonjour

Ejemplo 2:
English: goodbye
French: au revoir

Ejemplo 3:
English: thank you
French: merci

Ahora traduce:
English: cheese
French:
```

**Resultado:** El modelo aprende el patrÃ³n y responde mejor.

---

#### 2. Chain-of-Thought Prompting

**DefiniciÃ³n:**
Pedir al modelo que **muestre su razonamiento** paso a paso.

**Sin Chain-of-Thought:**
```
Prompt: "Roger tiene 5 pelotas. Compra 2 latas con 3 pelotas cada una. 
         Â¿CuÃ¡ntas tiene?"
         
Respuesta: 11 (sin explicaciÃ³n)
```

**Con Chain-of-Thought:**
```
Prompt: "Roger tiene 5 pelotas. Compra 2 latas con 3 pelotas cada una. 
         Â¿CuÃ¡ntas tiene? Explica paso a paso."
         
Respuesta: 
Paso 1: Roger empieza con 5 pelotas
Paso 2: 2 latas Ã— 3 pelotas = 6 pelotas nuevas
Paso 3: 5 + 6 = 11 pelotas
Respuesta final: 11 pelotas
```

**Ventaja:** Respuestas mÃ¡s precisas y verificables.

---

### Hallucination (AlucinaciÃ³n)

**DefiniciÃ³n:**
Cuando el LLM genera texto que es **factualmente incorrecto** o **no estÃ¡ fundamentado** en datos.

**Ejemplo:**
```
Prompt: Â¿CuÃ¡ndo empezaron a manejar por la izquierda en EE.UU.?

LLM (incorrecto): "En Estados Unidos, las personas gradualmente 
                   adoptaron la prÃ¡ctica de manejar por el lado 
                   izquierdo del camino..."

Realidad: En EE.UU. se maneja por la DERECHA.
```

---

### Reducir Hallucination

| MÃ©todo | DescripciÃ³n |
|--------|-------------|
| **RAG** | Fundamentar respuestas en documentos reales |
| **Few-shot** | Proporcionar ejemplos correctos |
| **Chain-of-Thought** | Pedir razonamiento paso a paso |
| **VerificaciÃ³n** | Siempre verificar informaciÃ³n crÃ­tica |

**Nota:** Actualmente NO existe un mÃ©todo 100% efectivo para eliminar alucinaciones.

---

## 7. Fine-Tuning de LLMs

### Â¿QuÃ© es Fine-Tuning?

**DefiniciÃ³n:**
Tomar un modelo **pre-entrenado** y entrenarlo adicionalmente con **datos especÃ­ficos** de tu dominio.

```
Modelo Pre-entrenado
(conocimiento general)
        â†“
    + Datos personalizados
    (conocimiento especÃ­fico)
        â†“
  Modelo Fine-tuned
(conocimiento general + especÃ­fico)
```

---

### Â¿CuÃ¡ndo Usar Fine-Tuning?

**Usa fine-tuning cuando:**
- âœ… El modelo no funciona bien en tu tarea
- âœ… Necesitas enseÃ±arle algo nuevo
- âœ… Quieres un estilo/tono especÃ­fico
- âœ… Dominio muy especializado (legal, mÃ©dico)

**No uses fine-tuning si:**
- âŒ Prompt engineering es suficiente
- âŒ No tienes datos etiquetados
- âŒ Los datos cambian frecuentemente

---

### Proceso de Fine-Tuning

```
1. Preparar datos
   â”œâ”€â”€ Formato: pares (input, output)
   â””â”€â”€ Cantidad: Miles de ejemplos
   
2. Entrenar modelo
   â”œâ”€â”€ Actualizar pesos
   â””â”€â”€ T-Few (eficiente) o Full fine-tuning
   
3. Evaluar
   â””â”€â”€ Probar en datos de test
   
4. Implementar
   â””â”€â”€ Usar modelo personalizado
```

---

### Ejemplo de Datos para Fine-Tuning

**Dominio: AtenciÃ³n al cliente de un banco**

```json
[
  {
    "input": "Â¿CÃ³mo abro una cuenta?",
    "output": "Para abrir una cuenta, necesitas: 1) IdentificaciÃ³n oficial, 2) Comprobante de domicilio, 3) Visitar una sucursal o hacerlo en lÃ­nea en nuestro portal."
  },
  {
    "input": "OlvidÃ© mi contraseÃ±a",
    "output": "Puedes restablecer tu contraseÃ±a en la app: 1) Toca 'OlvidÃ© contraseÃ±a', 2) Ingresa tu email, 3) Sigue las instrucciones del correo."
  }
]
```

**Necesitas:** Miles de ejemplos similares.

---

### Beneficios del Fine-Tuning

#### 1. Mejor DesempeÃ±o
```
Modelo base en dominio legal:
âŒ Respuestas genÃ©ricas
âŒ TÃ©rminos incorrectos

Modelo fine-tuned:
âœ… Respuestas especÃ­ficas
âœ… TerminologÃ­a legal correcta
```

#### 2. Mayor Eficiencia
```
Antes (prompt largo):
"Eres un experto legal. Conoces derecho mexicano. 
 Respondes formalmente. [1000 tokens de contexto]
 
 Pregunta del usuario: [10 tokens]"

DespuÃ©s (modelo fine-tuned):
"Pregunta del usuario: [10 tokens]"

Ahorro: 1000 tokens â†’ MÃ¡s rÃ¡pido y barato
```

---

## 8. Personalizar LLMs: Framework Completo

### Tres MÃ©todos Principales

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Eje Vertical (LLM)          â”‚
â”‚  OptimizaciÃ³n del LLM        â”‚
â”‚         â†‘                    â”‚
â”‚         â”‚  Fine-tuning       â”‚
â”‚         â”‚                    â”‚
â”‚         â”‚                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  â”‚
â”‚         â”‚                    â”‚
â”‚    Prompt    RAG             â”‚
â”‚  Engineering                 â”‚
â”‚                              â”‚
â”‚  Eje Horizontal (Contexto)   â”‚
â”‚  MÃ¡s informaciÃ³n especÃ­fica  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 1. Prompt Engineering

**CuÃ¡ndo:**
- âœ… Inicio rÃ¡pido
- âœ… Sin costos de entrenamiento
- âœ… LLM ya entiende el dominio

**Ejemplo:**
```
Usuario: "ActÃºa como un tutor de matemÃ¡ticas. 
          Explica paso a paso cÃ³mo resolver ecuaciones..."
```

---

### 2. RAG (Retrieval-Augmented Generation)

**CuÃ¡ndo:**
- âœ… Datos cambian frecuentemente
- âœ… Necesitas fundamentar respuestas
- âœ… Reducir alucinaciones

**Ventajas:**
- âœ… Acceso a informaciÃ³n actualizada
- âœ… Respuestas fundamentadas

**Desventajas:**
- âŒ Requiere base de datos compatible
- âŒ MÃ¡s complejo de configurar

---

### 3. Fine-Tuning

**CuÃ¡ndo:**
- âœ… LLM no funciona bien en tu tarea
- âœ… Datos demasiado grandes para prompt
- âœ… Necesitas estilo/tono especÃ­fico

**Ventajas:**
- âœ… Mejor desempeÃ±o
- âœ… Modelo mÃ¡s eficiente

**Desventajas:**
- âŒ Requiere datos etiquetados
- âŒ MÃ¡s recursos
- âŒ Tiempo de entrenamiento

---

### Estrategia Combinada

**Ruta tÃ­pica:**

```
Paso 1: Empezar con Prompt Engineering
  â”œâ”€â”€ Evaluar baseline
  â””â”€â”€ Probar few-shot

Paso 2: Â¿MejorÃ³?
  â”œâ”€â”€ SÃ­ â†’ Listo âœ…
  â””â”€â”€ No â†’ Siguiente paso

Paso 3: Agregar RAG
  â”œâ”€â”€ Conectar a knowledge base
  â””â”€â”€ Â¿MejorÃ³?
      â”œâ”€â”€ SÃ­ â†’ Listo âœ…
      â””â”€â”€ No â†’ Siguiente paso

Paso 4: Fine-tuning
  â”œâ”€â”€ Entrenar modelo personalizado
  â””â”€â”€ Â¿MejorÃ³?
      â”œâ”€â”€ SÃ­ â†’ Posiblemente combinar con RAG
      â””â”€â”€ No â†’ Iterar
```

---

## ğŸ“ Preguntas de PrÃ¡ctica para el Examen

### Pregunta 1
**Â¿QuÃ© enunciado describe con precisiÃ³n la IA generativa?**

- âœ… Crea contenido nuevo sin hacer predicciones
- â—‹ Entrena exclusivamente para predecir patrones de datos futuros
- â—‹ Limita funciones a generar solo salidas basadas en texto
- â—‹ Se enfoca en hacer predicciones precisas basadas en datos de entrenamiento

**ExplicaciÃ³n:** IA Generativa crea contenido nuevo, no solo predice.

---

### Pregunta 2
**El fine-tuning es innecesario para LLMs si tu aplicaciÃ³n NO involucra cuÃ¡l aspecto especÃ­fico?**

- â—‹ MitigaciÃ³n de sesgo
- â—‹ Vocabulario del dominio
- â—‹ Eficiencia y utilizaciÃ³n de recursos
- âœ… AdaptaciÃ³n especÃ­fica a tareas

**ExplicaciÃ³n:** Fine-tuning se realiza principalmente para adaptaciÃ³n a tareas especÃ­ficas.

---

### Pregunta 3
**Â¿QuÃ© aspecto de los LLMs impacta significativamente sus capacidades, desempeÃ±o y requisitos de recursos?**

- âœ… TamaÃ±o del modelo y parÃ¡metros, incluyendo nÃºmero de tokens y pesos
- â—‹ Complejidad de los lenguajes de programaciÃ³n usados
- â—‹ NÃºmero total de GPUs usadas para entrenamiento
- â—‹ NÃºmero de iteraciones durante el entrenamiento

**ExplicaciÃ³n:** El tamaÃ±o y nÃºmero de parÃ¡metros tienen impacto profundo en capacidades y desempeÃ±o.

---

## ğŸ“ Consejos para el Examen

### Diferencias Clave

| Concepto | DescripciÃ³n | Ejemplo |
|----------|-------------|---------|
| **GenAI** | Crea contenido nuevo | DALL-E genera imÃ¡genes |
| **ML** | Clasifica/Predice | Filtro de spam |
| **LLM** | Modelo de lenguaje grande | ChatGPT |

### Arquitecturas Transformer

| Tipo | Uso | Ejemplo |
|------|-----|---------|
| **Encoder-only** | Embeddings, bÃºsqueda | BERT |
| **Decoder-only** | GeneraciÃ³n de texto | GPT-4 |
| **Encoder-Decoder** | TraducciÃ³n | T5 |

### PersonalizaciÃ³n de LLMs

| MÃ©todo | CuÃ¡ndo | Ventaja |
|--------|--------|---------|
| **Prompt** | Inicio rÃ¡pido | Gratis, fÃ¡cil |
| **RAG** | Datos cambian | Actualizado |
| **Fine-tuning** | Dominio especÃ­fico | Mejor desempeÃ±o |

---

## ğŸ“š Resumen del MÃ³dulo

| Concepto | Puntos Clave |
|----------|--------------|
| **GenAI** | Crea contenido nuevo basÃ¡ndose en patrones |
| **LLM** | Modelo probabilÃ­stico de texto |
| **Transformer** | Arquitectura con self-attention |
| **Tokens** | Unidades bÃ¡sicas de procesamiento |
| **Embeddings** | RepresentaciÃ³n numÃ©rica de texto |
| **Prompt Engineering** | DiseÃ±o de inputs efectivos |
| **Fine-tuning** | PersonalizaciÃ³n de modelos |
| **RAG** | Fundamentar respuestas en documentos |

---

## âœ… Checklist de PreparaciÃ³n

Antes de avanzar, asegÃºrate de poder:

- [ ] Explicar la diferencia entre GenAI y ML tradicional
- [ ] Describir cÃ³mo funciona un LLM
- [ ] Entender la arquitectura Transformer
- [ ] Explicar self-attention
- [ ] Definir tokens y embeddings
- [ ] Aplicar tÃ©cnicas de prompt engineering
- [ ] Describir cuÃ¡ndo usar fine-tuning
- [ ] Explicar cÃ³mo funciona RAG